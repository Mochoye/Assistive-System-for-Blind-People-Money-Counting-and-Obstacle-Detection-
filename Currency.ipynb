{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soumedhik/Blind-Aid-Intel_OneApi_Hackathon/blob/main/Currency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVSPN-18LJGk",
        "outputId": "d7934264-26bf-4bf9-933a-0ccfd71f39cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load (likely expired) https://storage.googleapis.com/kaggle-data-sets/6209/9900/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240329%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240329T214509Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=77b03f0e77febc3542b6ab1238d0672a66b379b72fb8cc5ba106d11ce827f4e2519fa23396422c2ddd0157166273dbb9aff3454f3192a2099a9ef860d7d27fa97d0f896379b0006e6bab0559afe7a8a2eba8c66f3278b747130a8e8be08c1d6f709555456619b8019cd51bf52e584d84aa69f7e6826c3d7b94262088988a18a3d87e04d60cf1905ccef2c37b2c0e9ee83aec1940fa863a41f553596425b319fcf3eb46cfa1148f185a3a8947fa38986cc5ca1bfe16b0feddd9320db8f1916b497c366e14eaf36fea7be331211c7407b730aed902d312083d9ab85bf5bbddf851dcb33468547b9ca4928c8e39698e6a48c1fe37cd72bce063c9ad1719c52aa2bb to path /kaggle/input/resnet50\n",
            "Failed to load (likely expired) https://storage.googleapis.com/kaggle-data-sets/886101/1505106/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240329%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240329T214509Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2945f21b7619eff67f5e0550657afde52f17d3ebdc50b3e0d8dc037f05a8abc653704e4fa6b6900be96e992b4319574cb4c673349f7f374431a3762d6311c2b32ec2f951fee6e8b959d3e0eeae4ce2aa46564530b06605bd64cde02987cb6f833e86536d61bc47a626a783beb4339bed498306d42ad65f053cbac971c3bce4e366962af7d2ea9233112c0c86d9f948b0333e5cb0afa5be271f13ec80bad6d399a7a4542c25961ce7d7a48da56fd586e97ff93832048ed7b942a168dad5f74de2e5cc5511f0c25932bc9f9576226e5407ed0cc0596b0c4377462df6248c87f1421d8f76bed204dc60af32ed59b463f411900bf3a8586df8124cc058dc546bc7a8 to path /kaggle/input/indian-currency-note-images-dataset-2020\n",
            "Failed to load (likely expired) https://storage.googleapis.com/kaggle-data-sets/886652/1505707/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240329%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240329T214509Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0eda4c698f364833130a0f62e8d88b1d3a68c4cf6c6d499d0d248248ffd9c6289f50932a787f35fe67e95f4372aca7f95dbbe54806389de6cbbe5fb593fa7e030dc30a959c1e1ac971952cf4b715c1f203576a2a1330cd71dabab508ee003e01bad5ab2d7eb5f397b22fd22eecf111e995bff261045a1fb6cf283fd70fc4c84c816b094d56944d8c73b00fd3f6259159d1978adfedaa7b84a84764f0cd4dacd378b6b24ce93a6c72a518c8d292aa6525cbb7e4f343c539c29bb843a2a8cef5e0104a162e2926fef43788c0fde9f9feaf95c48238bf3fd8ec19801b7ce1ed5f909aa95feb3f1f8cf41702d431d3312148eb703f2179aad421c27c9dfdf40fb2d7 to path /kaggle/input/indian-currency-note-resnet-weights\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'resnet50:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F6209%2F9900%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240329%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240329T214509Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D77b03f0e77febc3542b6ab1238d0672a66b379b72fb8cc5ba106d11ce827f4e2519fa23396422c2ddd0157166273dbb9aff3454f3192a2099a9ef860d7d27fa97d0f896379b0006e6bab0559afe7a8a2eba8c66f3278b747130a8e8be08c1d6f709555456619b8019cd51bf52e584d84aa69f7e6826c3d7b94262088988a18a3d87e04d60cf1905ccef2c37b2c0e9ee83aec1940fa863a41f553596425b319fcf3eb46cfa1148f185a3a8947fa38986cc5ca1bfe16b0feddd9320db8f1916b497c366e14eaf36fea7be331211c7407b730aed902d312083d9ab85bf5bbddf851dcb33468547b9ca4928c8e39698e6a48c1fe37cd72bce063c9ad1719c52aa2bb,indian-currency-note-images-dataset-2020:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F886101%2F1505106%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240329%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240329T214509Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2945f21b7619eff67f5e0550657afde52f17d3ebdc50b3e0d8dc037f05a8abc653704e4fa6b6900be96e992b4319574cb4c673349f7f374431a3762d6311c2b32ec2f951fee6e8b959d3e0eeae4ce2aa46564530b06605bd64cde02987cb6f833e86536d61bc47a626a783beb4339bed498306d42ad65f053cbac971c3bce4e366962af7d2ea9233112c0c86d9f948b0333e5cb0afa5be271f13ec80bad6d399a7a4542c25961ce7d7a48da56fd586e97ff93832048ed7b942a168dad5f74de2e5cc5511f0c25932bc9f9576226e5407ed0cc0596b0c4377462df6248c87f1421d8f76bed204dc60af32ed59b463f411900bf3a8586df8124cc058dc546bc7a8,indian-currency-note-resnet-weights:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F886652%2F1505707%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240329%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240329T214509Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0eda4c698f364833130a0f62e8d88b1d3a68c4cf6c6d499d0d248248ffd9c6289f50932a787f35fe67e95f4372aca7f95dbbe54806389de6cbbe5fb593fa7e030dc30a959c1e1ac971952cf4b715c1f203576a2a1330cd71dabab508ee003e01bad5ab2d7eb5f397b22fd22eecf111e995bff261045a1fb6cf283fd70fc4c84c816b094d56944d8c73b00fd3f6259159d1978adfedaa7b84a84764f0cd4dacd378b6b24ce93a6c72a518c8d292aa6525cbb7e4f343c539c29bb843a2a8cef5e0104a162e2926fef43788c0fde9f9feaf95c48238bf3fd8ec19801b7ce1ed5f909aa95feb3f1f8cf41702d431d3312148eb703f2179aad421c27c9dfdf40fb2d7'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W6Eba4sLLJGq"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyzV9J5gMSvM",
        "outputId": "a070833a-0b18-4205-9c9b-373f7a1593d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: path in /usr/local/lib/python3.10/dist-packages (16.10.0)\n"
          ]
        }
      ],
      "source": [
        "pip install path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rm7abZq8LJGr"
      },
      "outputs": [],
      "source": [
        "#import basic essential libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import path\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# import  keras libraries to build model and conv net\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7SMyN8PaLJGs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "data_agumentation=ImageDataGenerator(rescale=0./255,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             vertical_flip=True\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_file_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/FINALMONEY.zip'\n",
        "\n",
        "# Directory to extract the contents to\n",
        "extract_to = '/content/'\n",
        "\n",
        "# Unzip the file\n",
        "unzip_file(zip_file_path, extract_to)\n"
      ],
      "metadata": {
        "id": "0t2kTvgXfMIx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Rx40J_eqLJGs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model=load_model('/content/currency_detector_2.4GB_earlyStopping_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5ig_Ci1ZLJGs"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "ZG8j9bZQLJGt",
        "outputId": "35f750b5-3c62-466e-da96-c044bc21da25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "# Display the model diagram\n",
        "plot_model(model, to_file='model_diagram.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "d4nqANYPLJGt"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "class_labels = [\n",
        "    '10','100','20','200','2000','50','500','Background'\n",
        "]\n",
        "\n",
        "def prediction(file_name):\n",
        "    img = image.load_img(file_name, target_size=(256,256))\n",
        "\n",
        "    image_to_test = image.img_to_array(img)\n",
        "\n",
        "    # Since Keras expects a list of images, not a single image,\n",
        "    # Add a fourth dimension to the image\n",
        "    list_of_images = np.expand_dims(image_to_test, axis=0)\n",
        "\n",
        "    # Make a prediction using the model\n",
        "    results = model.predict(list_of_images)\n",
        "\n",
        "    # Since we are only testing one image, we only need to check the first result\n",
        "    single_result = results[0]\n",
        "\n",
        "    # We will get a likelihood score for all possible classes.\n",
        "    # Find out which class had the highest score.\n",
        "    # The class with the highest likelihood is predicted as the result.\n",
        "    most_likely_class_index = int(np.argmax(single_result))\n",
        "    class_likelihood = single_result[most_likely_class_index]\n",
        "\n",
        "    # Get the name of the most likely class\n",
        "    class_label = class_labels[most_likely_class_index]\n",
        "\n",
        "    # Print the result\n",
        "    print(file_name)\n",
        "    print(\"This image is predicted as a {} with a likelihood of {:.2f}\".format(class_label, class_likelihood))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UhPguRzLJGu"
      },
      "outputs": [],
      "source": [
        "prediction(\"/content/360_F_356320611_FcuF3JcK9DIkAAPS8kbtHxZx8iS4Je8P.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEj9y-sNLJGu",
        "outputId": "bc7b8b53-2660-4319-d566-3dc239a05856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Collecting packaging<24,>=16.8 (from streamlit)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, packaging, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 packaging-23.2 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.32.2 watchdog-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odl_Th0KLJGv",
        "outputId": "83ebb097-ff2c-4546-a3a7-67ee1d7d38f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the pre-trained model\n",
        "34.32.188.114\n",
        "class_labels = ['10', '100', '20', '200', '2000', '50', '500', 'Background']\n",
        "\n",
        "def predict_currency(image_file):\n",
        "    img = image.load_img(image_file, target_size=(256, 256))\n",
        "    image_to_test = image.img_to_array(img)\n",
        "    list_of_images = np.expand_dims(image_to_test, axis=0)\n",
        "    results = model.predict(list_of_images)\n",
        "    most_likely_class_index = int(np.argmax(results[0]))\n",
        "    class_likelihood = results[0][most_likely_class_index]\n",
        "    class_label = class_labels[most_likely_class_index]\n",
        "    return class_label, class_likelihood\n",
        "\n",
        "def main():\n",
        "    st.title(\"Indian Currency Note Detector\")\n",
        "    uploaded_file = st.file_uploader(\"Upload an image of an Indian currency note\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file:\n",
        "        class_label, class_likelihood = predict_currency(uploaded_file)\n",
        "        st.image(uploaded_file, caption=f\"Predicted as {class_label} with likelihood {class_likelihood:.2f}\")\n",
        "        st.write(f\"This image is predicted as a {class_label} with a likelihood of {class_likelihood:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##PROPER APP.PY\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import subprocess\n",
        "import re\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load_model('/content/currency_detector_2.4GB_earlyStopping_model.h5')\n",
        "class_labels = ['10', '100', '20', '200', '2000', '50', '500', 'Background']\n",
        "\n",
        "def predict_currency(image_file):\n",
        "    img = image.load_img(image_file, target_size=(256, 256))\n",
        "    image_to_test = image.img_to_array(img)\n",
        "    list_of_images = np.expand_dims(image_to_test, axis=0)\n",
        "    results = model.predict(list_of_images)\n",
        "    most_likely_class_index = int(np.argmax(results[0]))\n",
        "    class_label = class_labels[most_likely_class_index]\n",
        "    st.write(f\"Predicted Amount for note {image_file.name}: {class_label} rs\")\n",
        "    return int(class_label)  # Return integer value of denomination\n",
        "def main():\n",
        "    st.markdown(\"<h1 style='text-align: center; color: #ff5733;'>Indian Currency Denomination Recognition and Calculation</h1>\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"<h2 style='text-align: center; color: #006400;'>By Soumedhik Bharati and Archisman Ray.</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Your existing code goes here\n",
        "\n",
        "    # Step 1: Upload images of Indian currency notes\n",
        "    original_array = []\n",
        "    num_notes = st.number_input(\"Enter the number of notes:\", min_value=1, step=1)\n",
        "\n",
        "    uploaded_files = []\n",
        "    for i in range(num_notes):\n",
        "        uploaded_file = st.file_uploader(f\"Upload an image of Indian currency note {i+1}\", key=f\"file_uploader_{i}\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "        if uploaded_file:\n",
        "            uploaded_files.append((i, uploaded_file))  # Store position and file tuple\n",
        "\n",
        "    # Step 2: Predict denominations from uploaded images and populate the original array\n",
        "    for position, uploaded_file in uploaded_files:\n",
        "        denomination = predict_currency(uploaded_file)\n",
        "        original_array.append((position, denomination))  # Store position and denomination\n",
        "\n",
        "    # Step 3: Transcribe the uploaded audio file and extract the total amount mentioned\n",
        "    audio_file = st.file_uploader(\"Upload the audio file\", type=[\"m4a\"])\n",
        "    if audio_file:\n",
        "        # Save the uploaded audio file temporarily\n",
        "        temp_audio_path = \"/tmp/uploaded_audio.m4a\"\n",
        "        with open(temp_audio_path, \"wb\") as f:\n",
        "            f.write(audio_file.read())\n",
        "\n",
        "        # Transcribe the saved audio file\n",
        "        try:\n",
        "            output = subprocess.check_output([\"whisper\", temp_audio_path, \"--model\", \"base\", \"--word_timestamps\", \"True\"]).decode(\"utf-8\")\n",
        "            # Split the output at the last occurrence of ']'\n",
        "            parts = output.split(']', 1)\n",
        "            if len(parts) > 1:\n",
        "                # If the split was successful, keep only the second part\n",
        "                transcription = parts[1].strip()  # strip() is used to remove leading and trailing whitespace\n",
        "            else:\n",
        "                # If the split was not successful, keep the whole output\n",
        "                transcription = output\n",
        "            st.write(f\"Transcription: {transcription}\")\n",
        "        except subprocess.CalledProcessError:\n",
        "            st.error(\"Error occurred while transcribing the audio. Please try again.\")\n",
        "            return\n",
        "\n",
        "        # Remove the temporary audio file\n",
        "        os.remove(temp_audio_path)\n",
        "\n",
        "        # Step 4: Extract the total amount mentioned in the transcription\n",
        "        match = re.search(r'\\b(\\d+(,\\d{3})*)\\b', transcription)\n",
        "        if match:\n",
        "            total_amount = int(match.group(1).replace(',', ''))  # Remove commas\n",
        "            st.write(f\"Total Amount: {total_amount}\")\n",
        "        else:\n",
        "            st.write(\"No number found in the transcription.\")\n",
        "            return\n",
        "\n",
        "        # Step 5: Sort the denominations based on their original positions\n",
        "        sorted_array = sorted(original_array, key=lambda x: x[0])\n",
        "\n",
        "        # Step 6: Initialize variables to track the remaining amount and the included notes\n",
        "        remaining_amount = total_amount\n",
        "        included_notes = []\n",
        "\n",
        "        # Step 7: Calculate the best denominations to meet the total amount\n",
        "        for position, denomination in sorted_array:\n",
        "            count = remaining_amount // denomination\n",
        "            if count > 0:\n",
        "                included_notes.extend([(position, denomination)] * count)\n",
        "                remaining_amount %= denomination\n",
        "\n",
        "        # Step 8: Display the included notes with their original positions\n",
        "        st.subheader(\"Denominations:\")\n",
        "        for position, denomination in included_notes:\n",
        "            st.write(f\"Note of {denomination} rs from position {position + 1}\")\n",
        "\n",
        "        # Step 9: Display the remaining change (if any)\n",
        "        if remaining_amount > 0:\n",
        "            st.write(f\"Remaining change: {remaining_amount} rs\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL2dQah1n7zy",
        "outputId": "15fce024-c29c-41a3-9cea-98c6cf729e24"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW9Mk7boLJGv",
        "outputId": "ec0c2316-1a0f-43e7-f98a-f3faa05386f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 3.48s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gUuRqAvNZRw",
        "outputId": "2984e58f-aa98-4e6a-9574-696b8f3aa50a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.32.188.114\n"
          ]
        }
      ],
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFeVhLNuNc5o",
        "outputId": "2e126617-bf39-4c19-f081-5f364acd3912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.32.188.114:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.903s\n",
            "your url is: https://easy-places-feel.loca.lt\n",
            "2024-04-03 21:21:49.839656: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-03 21:21:49.839753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-03 21:21:49.844724: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-03 21:21:51.466204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "2024-04-03 21:23:39.738 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 542, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 93, in <module>\n",
            "    main()\n",
            "  File \"/content/app.py\", line 63, in main\n",
            "    subtitle = transcription.split(\"find me \")[1].split(str(total_amount))[0]\n",
            "IndexError: list index out of range\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7b748bd6a440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7b748b15f880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 255ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 239ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 271ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 544ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 412ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 243ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 478ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 243ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 384ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 268ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92DeCh7gOEMl",
        "outputId": "da5904c5-31e1-4054-a0e1-3af05409a070"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-mbaxxu3n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-mbaxxu3n\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.3)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=2b224312b8b3eea61af52b13ab41257f7f105cc37712c499c526dfe3cdb4badc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-awocx12l/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z8Id3LKOuz7",
        "outputId": "e42fa395-0736-4336-c1a0-23e237d3e0e0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-aa7d5nl4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-aa7d5nl4\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=f62411f837f362bb49205d5e1fc75edcb5ee91fa6926c31ba124664413340961\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w34xh331/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "  Attempting uninstall: openai-whisper\n",
            "    Found existing installation: openai-whisper 20231117\n",
            "    Uninstalling openai-whisper-20231117:\n",
            "      Successfully uninstalled openai-whisper-20231117\n",
            "Successfully installed openai-whisper-20231117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOKA9pA6Pj_1",
        "outputId": "031d1e28-8554-4621-ef78-4b98bf11dfd0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 3,626 B/3,626 B 100\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [2 InRelea\u001b[0m\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                    \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [784 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,641 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,104 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,081 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,358 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,920 kB]\n",
            "Fetched 9,122 kB in 4s (2,437 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_numbers(sentence):\n",
        "    matches = re.findall(r'\\b(\\d+(,\\d{3})*)\\b', sentence)\n",
        "    numbers = [int(match[0].replace(',', '')) for match in matches]\n",
        "    return numbers\n",
        "\n",
        "sentence = \"The price is 1,200 rupees\"\n",
        "print(extract_numbers(sentence))  # Output: [1200]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn3mqrHR0Gg6",
        "outputId": "86a8d70c-93ef-4ff9-be94-d0e5dc1fdb08"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1200]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import subprocess\n",
        "import re\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load_model('../input/indian-currency-note-resnet-weights/currency_detector_2.4GB_earlyStopping_model.h5')\n",
        "class_labels = ['10', '100', '20', '200', '2000', '50', '500', 'Background']\n",
        "\n",
        "def predict_currency(image_file):\n",
        "    img = image.load_img(image_file, target_size=(256, 256))\n",
        "    image_to_test = image.img_to_array(img)\n",
        "    list_of_images = np.expand_dims(image_to_test, axis=0)\n",
        "    results = model.predict(list_of_images)\n",
        "    most_likely_class_index = int(np.argmax(results[0]))\n",
        "    class_likelihood = results[0][most_likely_class_index]\n",
        "    class_label = class_labels[most_likely_class_index]\n",
        "    return class_label, class_likelihood\n",
        "\n",
        "def main():\n",
        "    st.title(\"Indian Currency Note Denomination Calculator\")\n",
        "\n",
        "    # Step 1: Create the array of tuples with duplicate denominations\n",
        "    original_array = []\n",
        "    num_notes = st.number_input(\"Enter the number of notes:\", min_value=1, step=1)\n",
        "\n",
        "    uploaded_files = []\n",
        "    for _ in range(num_notes):\n",
        "        uploaded_file = st.file_uploader(\"Upload an image of an Indian currency note\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "        if uploaded_file:\n",
        "            uploaded_files.append(uploaded_file)\n",
        "\n",
        "    for uploaded_file in uploaded_files:\n",
        "        class_label, _ = predict_currency(uploaded_file)\n",
        "        original_array.append(int(class_label))\n",
        "\n",
        "    # Step 2: Sort the array based on the first element of each tuple (the value) in descending order\n",
        "    sorted_array = sorted([(value, index + 1) for index, value in enumerate(original_array)], key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    # Transcribe the audio using Whisper\n",
        "    audio_file = st.file_uploader(\"Upload the audio file\", type=[\"m4a\"])\n",
        "    if audio_file:\n",
        "        transcription = subprocess.check_output([\"whisper\", audio_file, \"--model\", \"base\", \"--word_timestamps\", \"True\"]).decode(\"utf-8\")\n",
        "\n",
        "        # Extract the number mentioned after \"find me\"\n",
        "        match = re.search(r'find me (\\d+)', transcription)\n",
        "        if match:\n",
        "            total_amount = int(match.group(1))\n",
        "\n",
        "            # Step 3: Initialize variables to track the total and the notes included\n",
        "            remaining_amount = total_amount\n",
        "            included_notes = []\n",
        "\n",
        "            # Step 4: Iterate through the sorted array and calculate the best denominations\n",
        "            for denomination, index in sorted_array:\n",
        "                count = remaining_amount // denomination\n",
        "                if count > 0:\n",
        "                    included_notes.extend([(denomination, index)] * count)\n",
        "                    remaining_amount %= denomination\n",
        "\n",
        "            # Step 5: Display the included notes with their original positions\n",
        "            st.subheader(\"Denominations:\")\n",
        "            for denomination, index in included_notes:\n",
        "                st.write(f\"Note of {denomination} rs from position {index}\")\n",
        "\n",
        "            # Step 6: Display the remaining change (if any)\n",
        "            if remaining_amount > 0:\n",
        "                st.write(f\"Remaining change: {remaining_amount} rs\")\n",
        "        else:\n",
        "            st.write(\"No number found in the transcription.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "X1EPdFaATyS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hiFgClRCso4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING"
      ],
      "metadata": {
        "id": "7liTYyjQqLhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Soumedhik/Blind-Aid-Intel_OneApi_Hackathon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1PuBVUbqTIJ",
        "outputId": "935151e5-b983-4529-d486-92cd1d530669"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Blind-Aid-Intel_OneApi_Hackathon'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 13 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (13/13), 113.88 KiB | 1.14 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezqo9x8UqamS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6209,
          "sourceId": 9900,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 886101,
          "sourceId": 1505106,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 886652,
          "sourceId": 1505707,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30121,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}